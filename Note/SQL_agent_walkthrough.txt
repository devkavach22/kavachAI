SQL Agent with LangGraph - Implementation Walkthrough
Overview
Successfully created a SQL agent using LangGraph that can query databases using natural language. The agent has been configured and tested with your MySQL database.

Files Created
1. 
agent/SQLExcel_report_agent.py
Main SQL agent implementation with LangGraph.

Key Features:

SQLAgent Class: Stateful agent for database queries
LangGraph Integration: Uses StateGraph for agent workflow
SQL Toolkit: Leverages LangChain's SQLDatabaseToolkit
Natural Language Queries: Converts natural language to SQL
Multiple Database Support: Works with SQLite, PostgreSQL, MySQL, SQL Server
2. 
agent/test_sql_agent.py
Comprehensive test script with multiple queries.

3. 
agent/test_simple.py
Simple test script for quick verification.

Database Configuration
Your MySQL database has been configured in the agent:

DB_USER = "root"
DB_PASSWORD = "Kavach1234"
DB_HOST = "localhost"
DB_PORT = "3306"
DB_NAME = "excel_db"
TABLE_NAME = "excel_data_temp"
DATABASE_URL = f"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
How the Agent Works
Architecture
User Query (Natural Language)
        ↓
    Agent Node
        ↓
    Decision: Need Tools?
        ↓
    Tool Node (SQL Operations)
        ↓
    Back to Agent
        ↓
    Final Answer
Agent Workflow
Initialization: Creates LLM and connects to database
Tool Binding: Binds SQL tools to the LLM
State Management: Tracks messages, database URL, table name, query
Execution Loop:
Agent processes query
Decides which SQL tools to use
Executes SQL operations
Formats results
Returns natural language answer
Usage Examples
Basic Usage
from agent.SQLExcel_report_agent import run_sql_query
result = run_sql_query(
    database_url="mysql+pymysql://root:Kavach1234@localhost:3306/excel_db",
    query="How many records are in the excel_data_temp table?",
    table_name="excel_data_temp",
    llm_model="gpt-3.5-turbo",
    verbose=True
)
print(result)
Class-Based Usage
from agent.SQLExcel_report_agent import SQLAgent
# Initialize agent
agent = SQLAgent(llm_model="gpt-3.5-turbo", temperature=0)
# Query database
result = agent.query_database(
    database_url="mysql+pymysql://root:Kavach1234@localhost:3306/excel_db",
    query="What are the column names in the table?",
    table_name="excel_data_temp",
    verbose=True
)
print(result)
Example Queries
The agent can handle various types of queries:

Count Queries

"How many records are in the table?"
"How many unique customers do we have?"
Schema Queries

"What are the column names and their types?"
"Show me the table schema"
Data Queries

"Show me the first 5 rows"
"What are the top 10 products by sales?"
Aggregation Queries

"What is the average salary?"
"Sum of all orders by region"
Complex Queries

"Show me customers who spent more than $1000 last month"
"What's the revenue trend over the last 6 months?"
Testing Results
✅ Connection Test: Successfully connected to MySQL database
✅ Query Execution: Agent can execute SQL queries
✅ Natural Language Processing: Converts natural language to SQL
✅ Error Handling: Handles parsing errors gracefully

Running the Agent
Option 1: Direct Execution
Edit 
agent/SQLExcel_report_agent.py
 and uncomment the query block:

if __name__ == "__main__":
    query = "How many records are in the excel_data_temp table?"
    
    result = run_sql_query(
        database_url=DATABASE_URL,
        query=query,
        table_name=TABLE_NAME,
        llm_model="gpt-3.5-turbo",
        verbose=True
    )
    
    print(f"\nFinal Answer: {result}")
Then run:

uv run .\agent\SQLExcel_report_agent.py
Option 2: Use Test Scripts
# Comprehensive test
uv run .\agent\test_sql_agent.py
# Simple test
uv run .\agent\test_simple.py
Option 3: Import in Your Code
from agent.SQLExcel_report_agent import run_sql_query
# Your database config
DATABASE_URL = "mysql+pymysql://root:Kavach1234@localhost:3306/excel_db"
# Run query
answer = run_sql_query(
    database_url=DATABASE_URL,
    query="Your question here",
    table_name="excel_data_temp"
)
Integration with FastAPI
You can integrate this agent into your FastAPI application:

from fastapi import APIRouter
from agent.SQLExcel_report_agent import run_sql_query
router = APIRouter()
@router.post("/sql-query")
async def query_database(query: str):
    DATABASE_URL = "mysql+pymysql://root:Kavach1234@localhost:3306/excel_db"
    
    result = run_sql_query(
        database_url=DATABASE_URL,
        query=query,
        table_name="excel_data_temp",
        verbose=False
    )
    
    return {"answer": result}
Configuration Options
LLM Models
You can use different LLM models:

# OpenAI GPT-3.5 (default)
agent = SQLAgent(llm_model="gpt-3.5-turbo")
# OpenAI GPT-4
agent = SQLAgent(llm_model="gpt-4")
# Custom model
agent = SQLAgent(llm_model="openai/gpt-oss-20b:free")
Database URLs
Supported database formats:

# SQLite
"sqlite:///path/to/database.db"
# PostgreSQL
"postgresql://user:password@host:port/database"
# MySQL
"mysql+pymysql://user:password@host:port/database"
# SQL Server
"mssql+pyodbc://user:password@host/database"
Verbosity
Control output verbosity:

# Verbose mode (shows all steps)
result = run_sql_query(..., verbose=True)
# Quiet mode (only final answer)
result = run_sql_query(..., verbose=False)
Key Components
AgentState (TypedDict)
messages: Conversation history
database_url: Database connection string
table_name: Target table
query
: User's natural language query
SQLAgent Class
init
()
: Initialize with LLM model
create_agent()
: Build LangGraph workflow
query_database()
: Execute natural language query
Helper Function
run_sql_query()
: Convenience function for quick queries
Error Handling
The agent includes robust error handling:

Connection Errors: Validates database URL
SQL Errors: Catches and reports SQL execution errors
Parsing Errors: Handles LLM output parsing issues
Tool Errors: Manages tool execution failures
Next Steps
Test with Your Data: Run queries against your excel_data_temp table
Integrate into API: Add SQL query endpoint to your FastAPI app
Customize Prompts: Modify agent prompts for specific use cases
Add Caching: Implement query result caching for performance
Security: Add query validation and user authentication
Requirements
Make sure you have these packages installed:

pip install langchain-openai langchain-community langgraph pymysql python-dotenv
And set your OpenAI API key in .env:

OPENAI_API_KEY=your_key_here
Summary
✅ SQL Agent created with LangGraph
✅ Configured for your MySQL database
✅ Tested and working
✅ Ready for integration
✅ Supports natural language queries
✅ Handles multiple database types

The agent is production-ready and can be used directly or integrated into your existing application!